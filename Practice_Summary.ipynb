{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9HcN6pc32S4bA1etbkNF+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YounSooKimTech/self_study/blob/main/Practice_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3adCraJdw2qd",
        "outputId": "11647a4a-e362-4ead-aa8f-422aabffa38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "import re\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_text = \"\"\"Artificial intelligence is human like intelligence.\n",
        "                   It is the study of intelligent artificial agents.\n",
        "                   Science and engineering to produce intelligent machines.\n",
        "                   Solve problems and have intelligence.\n",
        "                   Related to intelligent behavior.\n",
        "                   Developing of reasoning machines.\n",
        "                   Learn from mistakes and successes.\n",
        "                   Artificial intelligence is related to reasoning in everyday situations.\"\"\"\n",
        "original_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "AIJqcz9ZxEsP",
        "outputId": "7d2b538e-7665-42fb-9d23-50a7111ed6a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Artificial intelligence is human like intelligence. \\n                   It is the study of intelligent artificial agents. \\n                   Science and engineering to produce intelligent machines. \\n                   Solve problems and have intelligence. \\n                   Related to intelligent behavior. \\n                   Developing of reasoning machines. \\n                   Learn from mistakes and successes. \\n                   Artificial intelligence is related to reasoning in everyday situations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text preprocessing\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def preprocessing(text):\n",
        "  text = re.sub(r\"\\s+\", \" \", text)\n",
        "  text = text.lower()\n",
        "\n",
        "  tokens = []\n",
        "  for token in word_tokenize(text):\n",
        "    if token not in string.punctuation and token not in stopwords.words(\"english\"):\n",
        "      tokens.append(token)\n",
        "\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "formatted_text = preprocessing(original_text)\n",
        "formatted_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "zZH_SPBUxJQd",
        "outputId": "79c87564-ebb6-43af-8c2b-bb71e0c602f2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'artificial intelligence human like intelligence study intelligent artificial agents science engineering produce intelligent machines solve problems intelligence related intelligent behavior developing reasoning machines learn mistakes successes artificial intelligence related reasoning everyday situations'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a word frequency and their scores\n",
        "\n",
        "word_freq = nltk.FreqDist(nltk.word_tokenize(formatted_text))\n",
        "\n",
        "highest_freq = max(word_freq.values())\n",
        "highest_freq\n",
        "\n",
        "for key in word_freq.keys():\n",
        "  # print(key)\n",
        "  word_freq[key] = word_freq[key] / highest_freq\n",
        "\n",
        "word_freq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcADw8wDzQB3",
        "outputId": "a0b796fc-43d0-4905-f89e-7ea939b2b492"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'intelligence': 1.0, 'artificial': 0.75, 'intelligent': 0.75, 'machines': 0.5, 'related': 0.5, 'reasoning': 0.5, 'human': 0.25, 'like': 0.25, 'study': 0.25, 'agents': 0.25, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the sentence\n",
        "\n",
        "text = re.sub(r\"\\s+\", \" \", original_text)\n",
        "text\n",
        "\n",
        "sentence_list = sent_tokenize(text)\n",
        "sentence_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sLuebsTz6Ms",
        "outputId": "c80648cb-11aa-492d-88e6-52eb172572ce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artificial intelligence is human like intelligence.',\n",
              " 'It is the study of intelligent artificial agents.',\n",
              " 'Science and engineering to produce intelligent machines.',\n",
              " 'Solve problems and have intelligence.',\n",
              " 'Related to intelligent behavior.',\n",
              " 'Developing of reasoning machines.',\n",
              " 'Learn from mistakes and successes.',\n",
              " 'Artificial intelligence is related to reasoning in everyday situations.']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_sentences = {}\n",
        "for sentence in sentence_list:\n",
        "  #print(sentence)\n",
        "  for word in nltk.word_tokenize(sentence.lower()):\n",
        "    #print(word)\n",
        "    if sentence not in score_sentences.keys():\n",
        "      score_sentences[sentence] = word_freq[word]\n",
        "    else:\n",
        "      score_sentences[sentence] += word_freq[word]\n",
        "\n",
        "score_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZDrQY2i00V8",
        "outputId": "c9b6b120-2349-4edf-8e88-1b5e99dda13a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Artificial intelligence is human like intelligence.': 3.25,\n",
              " 'It is the study of intelligent artificial agents.': 2.0,\n",
              " 'Science and engineering to produce intelligent machines.': 2.0,\n",
              " 'Solve problems and have intelligence.': 1.5,\n",
              " 'Related to intelligent behavior.': 1.5,\n",
              " 'Developing of reasoning machines.': 1.25,\n",
              " 'Learn from mistakes and successes.': 0.75,\n",
              " 'Artificial intelligence is related to reasoning in everyday situations.': 3.25}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "best_sentences = heapq.nlargest(3, score_sentences, key = score_sentences.get)\n",
        "\n",
        "best_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhzctJFX1r4b",
        "outputId": "b408b6a4-1d8c-4bc1-8233-41adbf16ce77"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artificial intelligence is human like intelligence.',\n",
              " 'Artificial intelligence is related to reasoning in everyday situations.',\n",
              " 'It is the study of intelligent artificial agents.']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}