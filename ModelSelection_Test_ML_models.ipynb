{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj/iZJuCa3075SsWT9h3EI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YounSooKimTech/self_study/blob/main/ModelSelection_Test_ML_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the file which explain why I choose random forest classifier\n",
        "# So, this is the file for explanation\n",
        "# if you want to use the model, you can ignore this code file"
      ],
      "metadata": {
        "id": "Fm-5f_na7OHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LcRvgKfY4D6W"
      },
      "outputs": [],
      "source": [
        "# Javier made the label for the traiing dataset for L2 risk labeling! Thanks!\n",
        "# use fillna to prevent possible errros\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_excel('/content/BOS_RISKS (1).xlsx')\n",
        "df_train.head()\n",
        "\n",
        "# fill the NaN value as blank since having NaN can cuase a problem\n",
        "df_train[\"RISK_DESCRIPTION\"].fillna(\"\", inplace=True)\n",
        "df_train[\"Standard_risk_L2\"].fillna(\"\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install deep_translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTT_1oS64lUt",
        "outputId": "7d32a87c-8fd3-4c9a-bb07-996d127e8500"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translate the text to increase the number of data with labels to feed the model\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "def translate_in_english(text):\n",
        "  translated = GoogleTranslator(source=\"auto\", target=\"en\").translate(text)\n",
        "  return translated\n",
        "\n",
        "df_train[\"translated\"] = df_train[\"RISK_DESCRIPTION\"].apply(translate_in_english)"
      ],
      "metadata": {
        "id": "bQVVHIgT4d8n"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization for better processing\n",
        "# remove punctuation and number\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def tokenize_lemma_and_remove_stopwords_and_punctuation(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_.lower() for token in doc if not token.is_punct and not token.is_stop and not token.like_num]\n",
        "    tokens = [token for token in tokens if token.strip()]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df_train[\"text\"] = df_train[\"translated\"].apply(tokenize_lemma_and_remove_stopwords_and_punctuation)\n"
      ],
      "metadata": {
        "id": "oBVxr9JD4tem"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for convinience, train and test for X and y\n",
        "X = df_train['text']\n",
        "y = df_train['Standard_risk_L2']\n",
        "\n",
        "# split the dataset to test the models\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state= 42)\n",
        "\n",
        "# TF-IDF vectorization (trained by X_train)\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the number of features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "wbjS9Qhz4zD5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes Classifier\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "predicted_labels_nb = nb_classifier.predict(X_test_tfidf)\n",
        "\n",
        "accuracy_nb = accuracy_score(y_test, predicted_labels_nb)\n",
        "\n",
        "print(\"Accuracy (Naive Bayes):\", accuracy_nb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBpd_hnm6I_0",
        "outputId": "7d802ce7-65e9-45f9-e169-4d3ef7f4487b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Naive Bayes): 0.47058823529411764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression as a base model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression_classifier = LogisticRegression(random_state=42)\n",
        "logistic_regression_classifier.fit(X_train_tfidf, y_train)\n",
        "predicted_labels_lr = logistic_regression_classifier.predict(X_test_tfidf)\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test, predicted_labels_lr)\n",
        "\n",
        "print(\"Accuracy (Logistic Regression):\", accuracy_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJdmLT8w6zQM",
        "outputId": "6fa3b0a7-b2ce-4c2c-f2cc-0c8721233a6f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Logistic Regression): 0.5882352941176471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "predicted_labels_rf = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, predicted_labels_rf)\n",
        "\n",
        "print(\"Accuracy (Random Forest):\", accuracy_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDzbxObn5MRx",
        "outputId": "d9c04b88-ac32-4d75-c228-556496e480b4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Random Forest): 0.6078431372549019\n"
          ]
        }
      ]
    }
  ]
}